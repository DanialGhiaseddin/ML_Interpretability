{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from data.datasets import ClinicalCovid\n",
    "import numpy as np\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from augmentations import ClassificationSMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tabnet_utils import regularized_loss\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalization = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing of train set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "initial_drop_list = ['ID', 'cough', 'sputum', 'chills', 'Sore throat',\n",
    "                     'dizziness', 'stomachache', 'Diarrhea', 'Nausea',\n",
    "                     'runny nose', 'Nasal congestion', 'alcohol']\n",
    "\n",
    "train_set = ClinicalCovid('data/all_final.csv', drop_list=initial_drop_list)\n",
    "\n",
    "train_dropped_list = train_set.drop_missing_columns(threshold=0.5)\n",
    "train_set.fill_missing_data(n_dset=1, return_dset=0, iters=5, n_tree=50, print_kernel=False)\n",
    "# train_set.drop_missing_row()\n",
    "if normalization:\n",
    "    train_set.normalize()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set.dataframe.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set.raw_frame.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('imputed_data.pickle', 'wb') as h:\n",
    "    pickle.dump(train_set, h)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set.dataframe.head(10000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pretrain Network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_set.x.shape)\n",
    "print(train_set.y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aucs = []\n",
    "predictions = []\n",
    "probabilities = []\n",
    "ground_truth = []\n",
    "for i in range(20):\n",
    "    x_train, x_test, y_train, y_test = train_set.data_split(test_ratio=0.2, random_state=i)\n",
    "    y_train = y_train.ravel()\n",
    "    y_test = y_test.ravel()\n",
    "    print(f\"x_train:{x_train.shape}, y_train:{y_train.shape}\")\n",
    "    print(f\"x_test:{x_test.shape}, y_test:{y_test.shape}\")\n",
    "    unsupervised_model = TabNetPretrainer(\n",
    "        device_name='cpu',\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params=dict(lr=2e-2, weight_decay=0.0001),\n",
    "        mask_type='entmax',  # \"sparsemax\"\n",
    "        n_steps=1,\n",
    "        seed=40\n",
    "    )\n",
    "    unsupervised_model.fit(\n",
    "        X_train=x_train[0:1200],\n",
    "        max_epochs=130,\n",
    "        patience=100,\n",
    "        eval_set=[x_train[1200:]],\n",
    "        pretraining_ratio=0.8,\n",
    "    )\n",
    "    clf = TabNetClassifier(\n",
    "        device_name='cpu',\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params=dict(lr=2e-2),\n",
    "        n_steps=2,\n",
    "        scheduler_params={\"step_size\": 10,  # how to use learning rate scheduler\n",
    "                          \"gamma\": 0.9},\n",
    "        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "        mask_type='sparsemax',  # This will be overwritten if using pretrain model\n",
    "        seed=40\n",
    "    )\n",
    "\n",
    "    clf.fit(\n",
    "        X_train=x_train, y_train=y_train,\n",
    "        eval_set=[(x_train, y_train), (x_test, y_test)],\n",
    "        eval_name=['train', 'valid'],\n",
    "        eval_metric=['balanced_accuracy', 'accuracy', 'auc'],\n",
    "        weights=1,\n",
    "        max_epochs=200,\n",
    "        patience=100,\n",
    "        from_unsupervised=unsupervised_model,\n",
    "    )\n",
    "    aucs.append(np.max(np.asarray(clf.history['valid_auc'])))\n",
    "    preds = clf.predict(x_test)\n",
    "    probs = clf.predict_proba(x_test)\n",
    "    print(probs)\n",
    "    predictions.append(preds)\n",
    "    probabilities.append(probs)\n",
    "    ground_truth.append(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# aucs\n",
    "# predictions\n",
    "# probabilities\n",
    "# ground_truth\n",
    "print(np.mean(np.asarray(aucs)))\n",
    "print(np.std(np.asarray(aucs)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions[0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, fbeta_score, precision_score, recall_score, balanced_accuracy_score\n",
    "\n",
    "f1 = []\n",
    "f2 = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "accuracies = []\n",
    "for i, pred in enumerate(predictions):\n",
    "    y = ground_truth[i]\n",
    "    f1.append(f1_score(y, pred, pos_label=1, average='weighted'))\n",
    "    f2.append(fbeta_score(y, pred, pos_label=1, beta=2, average='weighted'))\n",
    "    precisions.append(precision_score(y, pred, pos_label=1, average='weighted'))\n",
    "    recalls.append(recall_score(y, pred, pos_label=1, average='weighted'))\n",
    "    accuracies.append(balanced_accuracy_score(y, pred))\n",
    "\n",
    "print(np.mean(np.asarray(f1)), np.std(np.asarray(f1)))\n",
    "print(np.mean(np.asarray(f2)), np.std(np.asarray(f2)))\n",
    "print(np.mean(np.asarray(precisions)), np.std(np.asarray(precisions)))\n",
    "print(np.mean(np.asarray(recalls)), np.std(np.asarray(recalls)))\n",
    "print(np.mean(np.asarray(accuracies)), np.std(np.asarray(accuracies)))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# x_categ = torch.randint(0, 5, (0, 0))     # category values, from 0 - max number of categories, in the order as passed into the constructor above\n",
    "# x_cont = torch.randn(1, 10)               # assume continuous values are already normalized individually\n",
    "# \n",
    "\n",
    "# pred = model(x_categ, x_cont) # (1, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def compute_auc(pred_logits, labels):\n",
    "    logits = pred_logits.softmax(dim=1)\n",
    "    logits = logits.detach().numpy()\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(labels, logits[:, 1], pos_label=1)\n",
    "    return metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "def plot_auc(pred_logits, labels):\n",
    "    logits = pred_logits.softmax(dim=1)\n",
    "    logits = logits.detach().numpy()\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(labels, logits[:, 1], pos_label=1)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.savefig('auc_test.tif')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "\n",
    "aucs = []\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "\n",
    "for i in range(20):\n",
    "\n",
    "    number_of_epochs = 4000\n",
    "    x_train, x_test, y_train, y_test = train_set.data_split(test_ratio=0.2, random_state=i)\n",
    "    y_train = y_train.ravel()\n",
    "    y_test = y_test.ravel()\n",
    "    print(f\"x_train:{x_train.shape}, y_train:{y_train.shape}\")\n",
    "    print(f\"x_test:{x_test.shape}, y_test:{y_test.shape}\")\n",
    "\n",
    "    t_train = torch.tensor(x_train)\n",
    "    t_test = torch.tensor(x_test)\n",
    "    y_train = torch.tensor(y_train)\n",
    "    y_train = y_train.type(torch.LongTensor)\n",
    "    y_test = torch.tensor(y_test)\n",
    "    y_test = y_test.type(torch.LongTensor)\n",
    "    cat_train = torch.randint(0, 5, (1599, 0))\n",
    "    cat_test = torch.randint(0, 5, (400, 0))\n",
    "    print(t_train.shape)\n",
    "    print(t_test.shape)\n",
    "    print(cat_train.shape)\n",
    "\n",
    "    model = TabTransformer(\n",
    "        categories=(),  #10, 5, 6, 5, 8 tuple containing the number of unique values within each category\n",
    "        num_continuous=110,  # number of continuous values\n",
    "        dim=32,  # dimension, paper set at 32\n",
    "        dim_out=2,  # binary prediction, but could be anything\n",
    "        depth=6,  # depth, paper recommended 6\n",
    "        heads=8,  # heads, paper recommends 8\n",
    "        attn_dropout=0.1,  # post-attention dropout\n",
    "        ff_dropout=0.1,  # feed forward dropout\n",
    "        mlp_hidden_mults=(4, 2),  # relative multiples of each hidden dimension of the last mlp to logits\n",
    "        mlp_act=nn.ReLU(),  # activation for final mlp, defaults to relu, but could be anything else (selu etc)\n",
    "        # continuous_mean_std = cont_mean_std # (optional) - normalize the continuous values before layer norm\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(number_of_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        logits = model(cat_train, t_train)\n",
    "        # print(pred.shape)\n",
    "        # print(y_train)\n",
    "        loss = criterion(logits, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.eval()\n",
    "        logits = model(cat_test, t_test)\n",
    "        auc = compute_auc(logits, y_test)\n",
    "        print(epoch, loss.item(), auc)\n",
    "    model.eval()\n",
    "    logits = model(cat_test, t_test)\n",
    "    auc = compute_auc(logits, y_test)\n",
    "    aucs.append(auc)\n",
    "    predictions.append(logits)\n",
    "    ground_truth.append(y_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "logits = model(cat_test, t_test)\n",
    "auc = plot_auc(logits, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.mean(np.asarray(aucs)))\n",
    "print(np.std(np.asarray(aucs)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.argmax(predictions[0], dim=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, fbeta_score, precision_score, recall_score, balanced_accuracy_score\n",
    "\n",
    "f1 = []\n",
    "f2 = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "accuracies = []\n",
    "for i, pred in enumerate(predictions):\n",
    "    pred = torch.argmax(pred, dim=1)\n",
    "    y = ground_truth[i]\n",
    "    f1.append(f1_score(y, pred, pos_label=1, average='weighted'))\n",
    "    f2.append(fbeta_score(y, pred, pos_label=1, beta=2, average='weighted'))\n",
    "    precisions.append(precision_score(y, pred, pos_label=1, average='weighted'))\n",
    "    recalls.append(recall_score(y, pred, pos_label=1, average='weighted'))\n",
    "    # print(recall_score(y, pred, pos_label=1, average='weighted'))\n",
    "    # print(accuracy_score(y, pred))\n",
    "    accuracies.append(balanced_accuracy_score(y, pred))\n",
    "\n",
    "print(np.mean(np.asarray(f1)), np.std(np.asarray(f1)))\n",
    "print(np.mean(np.asarray(f2)), np.std(np.asarray(f2)))\n",
    "print(np.mean(np.asarray(precisions)), np.std(np.asarray(precisions)))\n",
    "print(np.mean(np.asarray(recalls)), np.std(np.asarray(recalls)))\n",
    "print(np.mean(np.asarray(accuracies)), np.std(np.asarray(accuracies)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Supervised Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Interpret"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(preds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "norm_vec = np.sum(np.exp(preds), axis=1).reshape(-1, 1)\n",
    "print(norm_vec.shape)\n",
    "norm_vec = np.tile(norm_vec, (1, 2))\n",
    "\n",
    "p = np.exp(preds) / norm_vec\n",
    "\n",
    "print(p)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, theasholds = metrics.roc_curve(y_test, p[:, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(theasholds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, p[:, 1])\n",
    "\n",
    "# with open('tabnet_fpr.pkl', 'wb') as f:\n",
    "#     pickle.dump(fpr, f)\n",
    "#\n",
    "# with open('tabnet_tpr.pkl', 'wb') as f:\n",
    "#     pickle.dump(tpr, f)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "explain_matrix, masks = clf.explain(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "masks[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(np.mean(explain_matrix, axis=0))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.mean(masks[0], axis=0))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "temp_mask = masks[0]\n",
    "\n",
    "temp_mask[temp_mask > 0] = 1\n",
    "\n",
    "sns.heatmap(temp_mask, cmap='BuGn', square=True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(18, 12))\n",
    "my_colors = [(0.2, 0.3, 0.3), (0.4, 0.5, 0.4), (0.1, 0.7, 0), (0.1, 0.7, 0)]\n",
    "\n",
    "sns.heatmap(temp_mask, cmap=my_colors, square=True, linecolor=(0.1, 0.2, 0.2), ax=ax)\n",
    "\n",
    "# colorbar = ax.collections[0].colorbar\n",
    "# M=temp_mask.max().max()\n",
    "# colorbar.set_ticks([1/8*M,3/8*M,6/8*M])\n",
    "# colorbar.set_ticklabels(['low','med','high'])\n",
    "\n",
    "fig.show()\n",
    "fig.savefig('Outputs3/total.pdf')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds = clf.predict(x_test)\n",
    "norm_vec = np.sum(np.exp(preds), axis=1).reshape(-1, 1)\n",
    "norm_vec = np.tile(norm_vec, (1, 2))\n",
    "p = np.exp(preds) / norm_vec\n",
    "preds = np.argmax(preds, axis=1)\n",
    "print(preds.shape)\n",
    "print(np.sum(preds == y_test) / y_test.shape)\n",
    "print(confusion_matrix(y_test, preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p_1 = np.where(preds == 1)[0]\n",
    "r_1 = np.where(y_test == 1)[0]\n",
    "p_0 = np.where(preds == 0)[0]\n",
    "r_0 = np.where(y_test == 0)[0]\n",
    "\n",
    "t_expire = p_1[np.in1d(p_1, r_1)]\n",
    "f_expire = p_1[np.in1d(p_1, r_0)]\n",
    "\n",
    "t_alive = p_0[np.in1d(p_0, r_0)]\n",
    "f_alive = p_0[np.in1d(p_0, r_1)]\n",
    "false_cases = np.where(y_test != preds)[0]\n",
    "# false_cases = p_0[f_g]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "false_cases.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "explain_matrix, masks = clf.explain(x_test[t_expire])\n",
    "\n",
    "plt.plot(np.sum(explain_matrix, axis=0))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.sum(masks[0], axis=0))\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(np.sum(masks[1], axis=0))\n",
    "# plt.show()\n",
    "#\n",
    "# plt.plot(np.sum(masks[2], axis=0))\n",
    "# plt.show()\n",
    "\n",
    "temp = train_set.dataframe.columns.to_list()\n",
    "temp.remove('outcome')\n",
    "mask0 = pd.DataFrame(masks[0], columns=temp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mask0.head(1000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "explain_matrix, masks = clf.explain(x_test[t_alive])\n",
    "\n",
    "plt.plot(np.sum(explain_matrix, axis=0))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.sum(masks[0], axis=0))\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(np.sum(masks[1], axis=0))\n",
    "# plt.show()\n",
    "#\n",
    "# plt.plot(np.sum(masks[2], axis=0))\n",
    "# plt.show()\n",
    "\n",
    "temp = train_set.dataframe.columns.to_list()\n",
    "temp.remove('outcome')\n",
    "mask0 = pd.DataFrame(masks[0], columns=temp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CODE FOR PAPER"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "major_features_dict = dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selected_group = t_expire  # true_alive ,true_expire, false_cases\n",
    "group_name = 'true_expire'\n",
    "\n",
    "threshold = 0.3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "explain_matrix, masks = clf.explain(x_test[selected_group])\n",
    "\n",
    "mask = masks[0]\n",
    "\n",
    "mask[mask > 0] = 1\n",
    "\n",
    "mask = mask / mask.shape[0]\n",
    "\n",
    "col_names_list = train_set.dataframe.columns.to_list()\n",
    "col_names_list.remove('outcome')\n",
    "\n",
    "selected_df = pd.DataFrame(x_test[selected_group], columns=col_names_list)\n",
    "\n",
    "agg_mask = np.sum(mask, axis=0)\n",
    "major_features = []\n",
    "for i, col_name in enumerate(col_names_list):\n",
    "    if agg_mask[i] < threshold:\n",
    "        col_names_list[i] = ''\n",
    "    else:\n",
    "        major_features.append(col_name)\n",
    "\n",
    "major_features_dict[group_name] = major_features\n",
    "\n",
    "print(col_names_list)\n",
    "print(major_features)\n",
    "\n",
    "mask_agg = np.sum(mask, axis=0).tolist()\n",
    "\n",
    "if group_name == 'true_alive':\n",
    "    enumerate_object = enumerate(mask_agg)\n",
    "    sorted_pairs = sorted(enumerate_object, key=operator.itemgetter(1))\n",
    "    sorted_indices = [index for index, element in sorted_pairs]\n",
    "    sorted_indices = list(reversed(sorted_indices))\n",
    "\n",
    "mask_agg = np.asarray(mask_agg)\n",
    "\n",
    "col_names_list = [col_names_list[i] for i in sorted_indices]\n",
    "print(col_names_list)\n",
    "mask_agg = mask_agg[sorted_indices]\n",
    "mask = mask[:, sorted_indices]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xticks(range(len(col_names_list)))\n",
    "ax.set_xticklabels(col_names_list)\n",
    "plt.xticks(fontsize=6, rotation=90)\n",
    "\n",
    "ax.plot(mask_agg)\n",
    "fig.savefig(f'Outputs3/{group_name}_agg.pdf')\n",
    "\n",
    "temp = train_set.dataframe.columns.to_list()\n",
    "temp.remove('outcome')\n",
    "\n",
    "temp = [temp[i] for i in sorted_indices]\n",
    "\n",
    "mask_pd = pd.DataFrame(mask, columns=temp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# temp_mask = masks[0]\n",
    "#\n",
    "# temp_mask[temp_mask > 0] = 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 13))\n",
    "my_colors = [(0.2, 0.3, 0.3), (0.4, 0.5, 0.4), (0.1, 0.7, 0), (0.1, 0.7, 0)]\n",
    "ax.axes.get_yaxis().set_visible(False)\n",
    "ax.set_xticks(range(len(col_names_list)))\n",
    "ax.set_xticklabels(col_names_list)\n",
    "# plt.xticks(fontsize=6, rotation=90)\n",
    "# fig.axes[1].set_visible(False)\n",
    "\n",
    "ax1 = sns.heatmap(mask[:20], cmap=my_colors, square=True, linewidths=0.01, cbar=False, linecolor=(0.1, 0.2, 0.2), ax=ax)\n",
    "ax1.set_xticks(range(len(col_names_list)))\n",
    "ax1.set_xticklabels(col_names_list, rotation=90, fontsize=6)\n",
    "fig.savefig(f'Outputs3/{group_name}_heatmap.pdf')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for index, row in mask_pd.iterrows():\n",
    "    print(f\"Index: {index}\")\n",
    "    for key in row.keys():\n",
    "        if row[key] > 0:\n",
    "            print('\\t', key, selected_df.iloc[index][key])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mask_pd.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "major_features_dict.keys()\n",
    "venn_sets = []\n",
    "venn_labels = []\n",
    "for key in major_features_dict.keys():\n",
    "    print(key, major_features_dict[key])\n",
    "    venn_sets.append(set(major_features_dict[key]))\n",
    "    venn_labels.append(key)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3\n",
    "\n",
    "venn3(venn_sets, venn_labels)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "venn = venn3(venn_sets, venn_labels)\n",
    "\n",
    "venn.get_label_by_id('100').set_text('\\n'.join(venn_sets[0] - venn_sets[1] - venn_sets[2]))\n",
    "# venn.get_label_by_id('110').set_text('\\n'.join(venn_sets[0]&venn_sets[1]-venn_sets[2]))\n",
    "# venn.get_label_by_id('010').set_text('\\n'.join(venn_sets[1]-venn_sets[2]-venn_sets[0]))\n",
    "venn.get_label_by_id('101').set_text('\\n'.join(venn_sets[0] & venn_sets[2] - venn_sets[1]))\n",
    "venn.get_label_by_id('111').set_text('\\n'.join(venn_sets[0] & venn_sets[1] & venn_sets[2]))\n",
    "venn.get_label_by_id('011').set_text('\\n'.join(venn_sets[1] & venn_sets[2] - venn_sets[0]))\n",
    "venn.get_label_by_id('001').set_text('\\n'.join(venn_sets[2] - venn_sets[1] - venn_sets[0]))\n",
    "\n",
    "plt.savefig(f'Outputs3/venn.pdf')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_union = set()\n",
    "for key in major_features_dict.keys():\n",
    "    print(key, major_features_dict[key])\n",
    "    features_union = features_union.union(set(major_features_dict[key]))\n",
    "\n",
    "print(list(features_union))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols = train_set.dataframe.columns.to_list()\n",
    "cols.remove('outcome')\n",
    "\n",
    "for feature in features_union:\n",
    "    print(feature)\n",
    "\n",
    "    group = x_test[t_alive]\n",
    "    df = pd.DataFrame(group, columns=cols)\n",
    "    sns.distplot(df[feature], hist=False, kde=True, label='True Alive')\n",
    "\n",
    "    group = x_test[t_expire]\n",
    "    df = pd.DataFrame(group, columns=cols)\n",
    "    sns.distplot(df[feature], hist=False, kde=True, label='True Expire')\n",
    "\n",
    "    group = x_test[false_cases]\n",
    "    df = pd.DataFrame(group, columns=cols)\n",
    "    sns.distplot(df[feature], hist=False, kde=True, label='False cases')\n",
    "\n",
    "    # Plot formatting\n",
    "    plt.legend(prop={'size': 12})\n",
    "    plt.title(feature)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Density')\n",
    "    plt.savefig(f\"Outputs3/hist/{feature}.pdf\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correlation_mat = train_set.dataframe.corr()\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "sns.heatmap(correlation_mat)\n",
    "\n",
    "plt.savefig(f\"Outputs3/correlation.pdf\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correlation_mat['Headache']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_data = test_set.__orig_dat__.iloc[t_expire]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_data.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
